{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zmy2338/Machine-Learning-AWS/blob/main/TRAIN_AWS_P1_Lab_5_%5BSTUDENT%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab \\#5: Linear Regression**\n",
        "---\n",
        "\n",
        "**Description:**  In this lab, you will practice implementing linear regression models on three datasets. Linear regression is a statistical method for modeling the relationship between a dependent variable and one or more independent variables. Linear regression is widely used in various fields such as economics, finance, social sciences, and engineering for making predictions, understanding the nature of relationships between variables, and identifying important factors that contribute to the variability of the data. It is a fundamental tool for data analysis and is often one of the first models explored when working with a new dataset.\n",
        "\n",
        "</br>\n",
        "\n",
        "**About Datasets:**\n",
        "- **Boston Housing Dataset**: The Boston Housing Dataset is a collection of data that contains information on various features of houses in the Boston area, such as the number of rooms, the age of the house, and the distance to employment centers. The dataset is often used for regression analysis and is a popular benchmark dataset for machine learning algorithms.\n",
        "\n",
        "- **Diabetes Dataset**: The diabetes dataset includes various patient features such as BMI, age, blood pressure, and glucose levels, which can be used to predict disease progression in diabetic patients.\n",
        "\n",
        "- **California Housing Dataset**: The California Housing Dataset is a collection of data containing information on the median house value and other features of census block groups in California.\n",
        "</br>\n",
        "\n",
        "### **Lab Structure**\n",
        "**Part 1**: [Boston Housing Dataset](#p1)\n",
        "\n",
        "**Part 2**: [Diabetes Dataset](#p2)\n",
        "\n",
        "**Part 3**: [[OPTIONAL] California Housing Dataset](#p3)\n",
        "\n",
        "**Part 4**: [[ADDITIONAL PRACTICE] Zoo Animal Classification Dataset](#p4)\n",
        "\n",
        "</br>\n",
        "\n",
        "**Goals**: By the end of this lab, you will:\n",
        "* Implement a linear regression model on your own.\n",
        "* Test and use linear regression models to predict disease progression and housing prices.\n",
        "</br> \n",
        "\n",
        "### **Cheat Sheets**\n",
        "[EDA cheatsheet](https://drive.google.com/file/d/1ZZnIzgcT8dYcGwWVAR9DDFIwGXTGbIiU/view?usp=sharing)"
      ],
      "metadata": {
        "id": "YIlQ_30ypxfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the code below before continuing:**"
      ],
      "metadata": {
        "id": "t1PYlBJEq9DH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets, model_selection"
      ],
      "metadata": {
        "id": "2OiK0-eyq9e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"p1\"></a>\n",
        "\n",
        "## **Part 1: Boston Housing Dataset [Practice Together]**\n",
        "---\n",
        "The following dataset contains information on Boston housing and contains 13 numerical features and a numerical target. **Using several features, we are going to build a housing value predictor for Boston in the 1970s.** \n",
        "\n",
        "The features are as follows:\n",
        "\n",
        "* `CRIM`: Per capita crime rate by town\n",
        "* `ZN`: Proportion of residential land zoned for lots over 25,000 sq. ft\n",
        "* `INDU`S: Proportion of non-retail business acres per town\n",
        "* `CHAS`: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "* `NOX`: Nitric oxide concentration (parts per 10 million)\n",
        "* `RM`: Average number of rooms per dwelling\n",
        "* `AGE`: Proportion of owner-occupied units built prior to 1940\n",
        "* `DIS`: Weighted distances to five Boston employment centers\n",
        "* `RA`D: Index of accessibility to radial highways\n",
        "* `TAX`: Full-value property tax rate per 10,000 dolalrs\n",
        "* `PTRATIO`: Pupil-teacher ratio by town\n",
        "* `B`: 1000(Bk — 0.63)², where Bk is the proportion of [people of African American descent] by town\n",
        "* `LSTAT`: Percentage of lower status of the population\n",
        "* **`TARGET`** (target that needs to be added): Median value of owner-occupied homes in $1000s. *You need to add this column after loading the boston data from sklearn datasets*.\n",
        "\n",
        "<br>\n",
        "\n",
        "**NOTE:** The Boston housing prices dataset has a noted ethical problem: the authors of this dataset engineered a non-invertible variable “B” assuming that racial self-segregation had a positive impact on house prices. This variable is likely due to the practice of ['Redlining'](https://www.wgbh.org/news/local-news/2019/11/12/how-a-long-ago-map-created-racial-boundaries-that-still-define-boston) from the 1930s to 1970s in Boston, which has had long lasting affects in Boston still present today. The goal of the research that led to the creation of this dataset was to study the impact of air quality, but it did not give adequate demonstration of the validity of this assumption. Please know this data set is used for *practice only* and can serve as a good example of why ethical standards are so important for ML models and implementation. [Read more](https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8) on problems existing within this data set and why it is not used for anything other than practicing ML."
      ],
      "metadata": {
        "id": "3f6t0yYBhCsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #1: Load the data**"
      ],
      "metadata": {
        "id": "Jrbb0BuorRTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df = df.rename(columns={'medv': 'TARGET', 'rm': 'RM', 'lstat':'LSTAT'})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "3X4RLiyYizVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #2: Decide independent and dependent variables**\n",
        "We are going to use \"Rooms per dwelling\" (`RM`) and \"Percentage of lower status of the population\" (`LSTAT`) as our dependent variables for predicting `TARGET`. Our target is the median value of owner-occupied homes. **With these values, we are building a housing value predictor for Boston in the 1970s.**"
      ],
      "metadata": {
        "id": "HYlGaXV3rZfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[[\"RM\",\"LSTAT\", \"TARGET\"]]"
      ],
      "metadata": {
        "id": "uU0u-IaDizsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Before we continue, create two graphs. One with `LSTAT` and the target, and another with `RM` and the target to explore the relationship between the variables further.**"
      ],
      "metadata": {
        "id": "q_eLEi5MiiPb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7HBOCYkknwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Solution**"
      ],
      "metadata": {
        "id": "jZ3cn2MTkjbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "\n",
        "features = ['LSTAT', 'RM']\n",
        "target = df['TARGET']\n",
        "\n",
        "for i, col in enumerate(features):\n",
        "    plt.subplot(1, len(features) , i+1)\n",
        "    x = df[col]\n",
        "    y = target\n",
        "    plt.scatter(x, y, marker='o')\n",
        "    plt.title(col)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('target')"
      ],
      "metadata": {
        "id": "BxDxSgcoi0Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #3: Split data into training and testing data**\n"
      ],
      "metadata": {
        "id": "HAWp_v2XsGp0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KvDFJJYEkp8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Solution**"
      ],
      "metadata": {
        "id": "F1m4Baugkpsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(df[[\"RM\", \"LSTAT\"]], df[[\"TARGET\"]], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "hg_kivmJi0hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #4: Import your algorithm**\n",
        "Import sklearn's linear regression algorithm."
      ],
      "metadata": {
        "id": "fF3UEeSjsQIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import that LinearRegression algorithm\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "aZPn1IAIixnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #5: Initialize your model and set hyperparameters**\n",
        "Linear regression takes no hyperparameters, so just initialize the model."
      ],
      "metadata": {
        "id": "a--9MAucsbP_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B_zQuzK3kuKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Solution**"
      ],
      "metadata": {
        "id": "lmd5YGxcktQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize\n",
        "reg = LinearRegression()"
      ],
      "metadata": {
        "id": "Xr0JvwcgDYKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #6: Fit your model, test on the testing data, and create a visualization if applicable**\n"
      ],
      "metadata": {
        "id": "wzsWL1-jssDD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CP2QQOaBkwlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Solution**"
      ],
      "metadata": {
        "id": "WakkcKmKkvJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit\n",
        "reg.fit(X_train, y_train)\n",
        "# predict\n",
        "pred = reg.predict(X_test)"
      ],
      "metadata": {
        "id": "dMEVWZ33DcSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a visualization**\n",
        "\n",
        "Use `y_test` and your `prediction` (x and y on graph) from the model to create a scatter plot. Then use the following line to visualize where a correct prediction would be:\n",
        "```\n",
        "plt.plot([0, 50], [0, 50], '--k', label=\"Correct prediction\")\n",
        "```"
      ],
      "metadata": {
        "id": "u4EGuo2BvAWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(y_test, pred)\n",
        "plt.plot([0, 50], [0, 50], '--k', label=\"Correct prediction\")\n",
        "plt.axis('tight')\n",
        "plt.xlabel('True price ($1000s)')\n",
        "plt.ylabel('Predicted price ($1000s)')\n",
        "plt.title(\"Real vs predicted house prices in Boston\")\n",
        "plt.legend()\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "AkCjm5-JmaLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #7: Evaluate your model**\n",
        "\n",
        "Use mean squared error and the R2 score as the evaluation metrics."
      ],
      "metadata": {
        "id": "MRav6EEBtEdO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3r_jos6skz7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Solution**"
      ],
      "metadata": {
        "id": "1VTyWmGnky_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "print('mean squared: ', mean_squared_error(y_test, pred))\n",
        "print('R2 score: ', r2_score(y_test, pred))\n"
      ],
      "metadata": {
        "id": "AHcYv6SGLzAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82955d09-0f62-47c1-e14b-e1ff18b83014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean squared:  31.243290601783627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #8: Use the model**\n",
        "Using the model we created, predict the price of two houses in Boston:\n",
        "\n",
        "* House 1:  7 `RM` and `LSTAT` is 5.0%\n",
        "\n",
        "* House 2:  6 `RM` and `LSTAT` is 4.0%\n",
        "\n",
        "**Note:** you must create a dataframe containing with the information of the new houses:\n",
        "\n",
        "```python\n",
        "new_houses = pd.DataFrame(enter_new_house_data_here, columns =[\"RM\", \"LSTAT\"])\n",
        "```\n",
        "\n",
        "This `new_houses` variable can then be placed directly into the `model.predict()` function."
      ],
      "metadata": {
        "id": "FP-SqsUctlcO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZueyRpTMk2JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Solution**"
      ],
      "metadata": {
        "id": "8w08Ofqgk1Rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_houses = pd.DataFrame([[7,5], [6,4]], columns =[\"RM\", \"LSTAT\"])\n",
        "new_prediction = reg.predict(new_houses)\n",
        "print('prediction: ', new_prediction)"
      ],
      "metadata": {
        "id": "6JBDlLDgQ2dC",
        "outputId": "7f8de37e-e162-4b1a-f5a5-06f4cdbd9844",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction:  [[31.25202152]\n",
            " [26.41942131]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"p2\"></a>\n",
        "\n",
        "## **Part 2: Diabetes Dataset**\n",
        "---\n",
        "This dataset contains data from diabetic patients with features such as their BMI, age, blood pressure, and glucose levels that are useful in predicting the diabetes disease progression in patients. We will be looking at these variables that will be used to help predict disease progression in diabetic patients. Note that similar to the above, we will be using the 8-steps of the Machine Learning Process. \n",
        "\n",
        "**Steps of the ML Process:**\n",
        "1. **Load the data**\n",
        "2. **Decide independent variables and dependent variables**\n",
        "3. **Split the data into training and test data**\n",
        "4. **Import the model**\n",
        "5. **Initialize the model and set hyperparameters**\n",
        "6. **Fit your model, test on the testing data, and create a visualization if applicable**\n",
        "7. **Evaluate your model**\n",
        "8. **Use the model**\n"
      ],
      "metadata": {
        "id": "A0CMPq525kSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #1: Load the data**\n",
        "The following code will load the data. Turn this into a date frame.\n",
        "```python\n",
        "diabetes = datasets.load_diabetes()\n",
        "```\n",
        "Add a column called `TARGET` with the target data (`diabetes.target`).  In this case, the target is a measure for disease progression."
      ],
      "metadata": {
        "id": "YQPB7XZ9v-sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes = datasets.load_diabetes()\n",
        "df = pd.DataFrame(data=diabetes.data, columns=diabetes.feature_names)\n",
        "## YOUR CODE HERE ##\n",
        "df"
      ],
      "metadata": {
        "id": "a3hrfMNhk5mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #2: Decide independent and dependent variables**\n",
        "Here we would like to use the `age` `bmi` and `bp` columns as our dependent variables and the `TARGET` as our independent variable.\n",
        "\n",
        "We are building a predictor of disease progression.\n"
      ],
      "metadata": {
        "id": "E5z0mLEQF565"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['age', 'bmi', 'bp', \"TARGET\"]]"
      ],
      "metadata": {
        "id": "QQcn56UyGHS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #3: Split data into training and testing data**\n",
        "Use `age`, `bmi`, and `bp` for our independent variables."
      ],
      "metadata": {
        "id": "lMDn8ONk600c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IOuMRPdQlAVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #4: Import your model**\n"
      ],
      "metadata": {
        "id": "5ADG4KRM69dJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VZMm4IAClBLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #5: Initialize your model and set hyperparameters**\n",
        "Linear regression takes no hyperparameters, so just initialize the model."
      ],
      "metadata": {
        "id": "PFUiA67CHAMc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "faXqWmQElEFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #6: Fit your model, test on the testing data, and create a visualization if applicable**"
      ],
      "metadata": {
        "id": "xMnlj4W0HF9U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h5iPDJmJlFAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a visualization**\n",
        "\n",
        "Use `y_test` and your `prediction` from the model to create a scatter plot. Then use the following line to visualize where a correct prediction would be.\n",
        "\n",
        "**This has already been done for you.**\n",
        "```\n",
        "plt.plot([0, 300], [0, 300], '--k', label=\"Correct prediction\")\n",
        "```"
      ],
      "metadata": {
        "id": "6DmQtTt9HNJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(y_test, pred)\n",
        "plt.plot([0, 300], [0, 300], '--k', label=\"Correct prediction\")\n",
        "plt.axis('tight')\n",
        "plt.xlabel('True Progression')\n",
        "plt.ylabel('Predicted Progression')\n",
        "plt.title(\"Real vs predicted Disease Progression in Diabetic Patients\")\n",
        "plt.legend()\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "ZXX56Q1rHRM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #7: Evaluate your model**\n"
      ],
      "metadata": {
        "id": "9hqWuSqc7Tpp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Q0ABlESlNDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #8: Use the model**\n",
        "Using the model we created, predict the disease progression of two new patients:\n",
        "\n",
        "* Patient 1:  0.0045 `age` 0.053 `bmi` 0.014 `bp`\n",
        "\n",
        "* Patient 2:  0.0039 `age` -0.012 `bmi` 0.018 `bp`\n",
        "\n",
        "**Note:** you must create a dataframe containing with the information of the new patients:\n",
        "\n",
        "```python\n",
        "new_patient_data = pd.DataFrame(new_patient_data_here, columns =[\"age\", \"bmi\", \"bp\"])\n",
        "```"
      ],
      "metadata": {
        "id": "kKm0SpTVQMkn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GTtU_xbJQ0QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"p3\"></a>\n",
        "\n",
        "## **Part 3: California Housing Dataset [Optional]**\n",
        "---\n",
        "This dataset was derived from the 1990 U.S. Census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people)\n",
        "\n",
        "The target variable is the median house value for California districts, expressed in hundreds of thousands of dollars ($100,000). We will use the data to help make a model that will predict the median house value in California in 1990.\n",
        "\n",
        "**Specifically create a linear regression model and predict the median house value of a district that has: 7.2 average rooms, 1.5 average bedrooms, 51 years old, located at 38.1 Latitude, -121.08 Longitude. *Try different independent variables for your model and see how the accuracy changes.***\n"
      ],
      "metadata": {
        "id": "aF6K9Aot78B8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #1: Load the data**"
      ],
      "metadata": {
        "id": "r5TPUa-PyKKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import relevant packages\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 1\n",
        "cali_data = fetch_california_housing()\n",
        "df = pd.DataFrame(data=cali_data.data, columns=cali_data.feature_names)\n",
        "df['TARGET'] = cali_data.target"
      ],
      "metadata": {
        "id": "a0Zp2GECIZUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #2: Decide independent and dependent variables**\n",
        "The dependent variables will be the `TARGET`, so find the best independent variables using `.var()` and `.corr()`."
      ],
      "metadata": {
        "id": "jTc99Mtg0eAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# var"
      ],
      "metadata": {
        "id": "ZNNA3ZHsldnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# corr"
      ],
      "metadata": {
        "id": "6m2xamF1ldXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Steps #3-6: Split data, import/initialize your model, fit the model, make a prediction, and create a visualization**"
      ],
      "metadata": {
        "id": "-1TLEQbGySOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 - nothing to do here, we just used all columns except for AveRooms\n",
        "\n",
        "# 3 \n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['HouseAge',\t'AveBedrms','Latitude',\t'Longitude']], df['TARGET'], test_size=0.2)\n",
        "\n",
        "# 4 - 6\n"
      ],
      "metadata": {
        "id": "RdQ2N7uDlmu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6 part two: visualization\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RHwjXtO5lsla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Steps #7-8: Evaluate and use the model**"
      ],
      "metadata": {
        "id": "Sr_2Pqe9yrfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8 \n",
        "\n",
        "\n",
        "# 9"
      ],
      "metadata": {
        "id": "6G9WKzEolwOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## [OPTIONAL] **Part 4: Zoo Animal Classification Dataset**\n",
        "---\n",
        "The following dataset contains information on various zoo animals, including their characteristics and classifications. Our goal is to build a model that predicts the classification of an animal based on its features.\n",
        "\n",
        "The features are as follows:\n",
        "\n",
        "\n",
        "*    `animal_name`: Name of the animal\n",
        "*   `hair`: Hair presence (1 if present, 0 if not)\n",
        "- `feathers`: Feather presence (1 if present, 0 if not)\n",
        "-     `eggs`: Egg-laying ability (1 if yes, 0 if no)\n",
        "-    ` milk`: Milk production ability (1 if yes, 0 if no)\n",
        "-     `airborne`: Ability to fly (1 if yes, 0 if no)\n",
        "-     `aquatic`: Ability to live in water (1 if yes, 0 if no)\n",
        "- `predator`: Predatory behavior (1 if yes, 0 if no)\n",
        "- `toothed`: Teeth presence (1 if present, 0 if not)\n",
        "- `backbone`: Backbone presence (1 if present, 0 if not)\n",
        "-  `breathes`: Ability to breathe (1 if yes, 0 if no)\n",
        "- `venomous`: Venom presence (1 if present, 0 if not)\n",
        "- `fins`: Fin presence (1 if present, 0 if not)\n",
        "- `legs`: Number of legs (numeric)\n",
        "- `tail`: Tail presence (1 if present, 0 if not)\n",
        "- `domestic`: Domestication status (1 if domestic, 0 if not)\n",
        "- `catsize`: Animal size (1 if cat-size or larger, 0 if smaller)\n",
        "- `class_type`: Numeric class identifier (1-7)"
      ],
      "metadata": {
        "id": "2I1Jg2wSymZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #1: Load the data**"
      ],
      "metadata": {
        "id": "uALsY1jv0OtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/zoo/zoo.data\"\n",
        "\n",
        "# Create dataframe\n",
        "column_names = ['animal_name', 'hair', 'feathers', 'eggs', 'milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes', 'venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']\n",
        "df = pd.read_csv(url, names=column_names)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "pg99h8lr0L0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #2: Decide independent and dependent variables**\n",
        "We are going to use all features except `animal_name` and `class_type` as our independent variables for predicting class_type.\n",
        "\n"
      ],
      "metadata": {
        "id": "5DJtkoHn0bL8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f7-0cUep0naJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #3: Split data into training and testing data**"
      ],
      "metadata": {
        "id": "5omgCtfW1i4U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uE_3S_vw1mIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #4: Import your algorithm**\n",
        "Import sklearn's DecisionTreeClassifier algorithm."
      ],
      "metadata": {
        "id": "rrBakbiK1qGv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0-KRBRBN1s3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #5: Initialize your model and set hyperparameters**\n",
        "Initialize the DecisionTreeClassifier model."
      ],
      "metadata": {
        "id": "EEBL8QJ811ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qPq8Sokb167W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #6: Fit your model, test on the testing data**"
      ],
      "metadata": {
        "id": "xTpPtWDz1-YZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J7s6t9fF2BnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step #7: Evaluate your model**\n",
        "Use `accuracy_score` as the evaluation metric."
      ],
      "metadata": {
        "id": "rDLJpe_f2FH_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0GWgHE8q2MQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reflection question:** How accurately was your algorithm able to predict the type of species?"
      ],
      "metadata": {
        "id": "ZdL3WREd31IV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''\n",
        "\n",
        "'Your Answer Here'\n",
        "\n",
        "\n",
        "''"
      ],
      "metadata": {
        "id": "B9wE9MKlyEsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Congratulations on finishing this notebook!** In this lab, we practiced implementing linear regression models on three datasets: Boston Housing Dataset, Diabetes Dataset, and California Housing Dataset. We learned how to load and explore datasets, split data into training and testing data, and implement a linear regression algorithm in Python using `scikit-learn`."
      ],
      "metadata": {
        "id": "LQ95yR525HRl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "© 2023 The Coding School, All rights reserved"
      ],
      "metadata": {
        "id": "yt29TPJXhU9Q"
      }
    }
  ]
}