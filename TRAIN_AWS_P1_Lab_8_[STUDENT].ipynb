{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3TJ6CbLh-rxa"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zmy2338/Machine-Learning-AWS/blob/main/TRAIN_AWS_P1_Lab_8_%5BSTUDENT%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab #8 : Logistic Regression**\n",
        "---\n",
        "\n",
        "### **Description**\n",
        "In this lab, we'll learn how to use logistic regression to classify data into different categories. We'll start with binary classification, where the goal is to separate data into two categories. We'll revisit the breast cancer dataset, which consists of biopsied breast tissue samples that are classified as either malignant or benign. This is the same dataset we used in Lab 6 with the KNN model.\n",
        "\n",
        "In the second part of the lab, we'll move on to multiclass classification, where the goal is to separate data into more than two categories. We'll use the Digits dataset, which consists of images of handwritten digits, with each image represented as an 8x8 array of grayscale pixels.\n",
        "\n",
        "For both of these parts, we'll use pandas to load and preprocess the data, matplotlib to visualize it, and scikit-learn (sklearn) to build and evaluate the logistic regression model.\n",
        "\n",
        "Finally, we'll return to the Titanic dataset from Kaggle and compare the performance of KNN and Logistic Regression models to see which performs best on the dataset.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "### **Datasets**\n",
        "\n",
        "> For the binary classification part of the lab, we'll use the **Breast Cancer Wisconsin (Diagnostic) dataset**, which can be loaded using scikit-learn's `load_breast_cancer` function. The dataset consists of 569 samples of biopsied breast tissue, each described by 30 features. The goal is to classify each tissue sample as either malignant (cancerous) or benign (non-cancerous).\n",
        "\n",
        "> For the multiclass classification part of the lab, we'll use the **Digits dataset**, which can be loaded using scikit-learn's `load_digits` function. The dataset consists of 1,797 images of handwritten digits, with each image represented as an 8x8 array of grayscale pixels. The goal is to classify each image into one of 10 classes, corresponding to the digits 0-9.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Lab Structure**\n",
        "**Part 1**: Binary Classification\n",
        "\n",
        "**Part 2**: Multiclass Classification\n",
        "\n",
        "**Part 3**: Titanic Project Continued: Battle of the Models\n",
        "\n",
        "> **Part 3.1:** Build, Train, and Validate Models\n",
        "\n",
        "> **Part 3.2:** [OPTIONAL] Make Predictions\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Goals** \n",
        "By the end of this lab, you will:\n",
        "* Know how to implement logistic regression for binary classification.\n",
        "* Know how to implement logistic regression for multiclass classification.\n",
        "* Understand how to validate models by choosing an appropriate metric and using the validation dataset.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Cheat Sheets**\n",
        "[Logistic Regression with sklearn](https://docs.google.com/document/d/1rLTuWGgx9E-K1pgWYxUF4B1ExKKxt6MVSkgEKoUbhuE/edit?usp=sharing)\n",
        "\n",
        "<br>\n",
        "\n",
        "**Before starting, run the code below to import all necessary functions and libraries.**\n"
      ],
      "metadata": {
        "id": "mbZXQ3rA3NwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer, load_digits\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "YAvvLhRIoqYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Part 1: Binary Classification**\n",
        "---\n",
        "\n",
        "In this lab, we'll learn how to use logistic regression to classify breast cancer tumors as malignant or benign. We'll use pandas to load and preprocess the data, matplotlib to visualize it, and scikit-learn (sklearn) to build and evaluate the logistic regression model."
      ],
      "metadata": {
        "id": "idga37M2FsMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The code for loading the dataset has been provided for you. Run the cell below.**"
      ],
      "metadata": {
        "id": "tuLrNlbxoZiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_breast_cancer()\n",
        "\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target"
      ],
      "metadata": {
        "id": "pdkqQq0h1TMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem #1: Print a summary of the dataset.**\n",
        "---"
      ],
      "metadata": {
        "id": "w_y6J2dod4qL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zdrHqvXFd-8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data has been pre-cleaned so we can move on to modeling."
      ],
      "metadata": {
        "id": "dfopq4VXeN6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem #2: Split the data into train and test sets.**\n",
        "---\n",
        "\n",
        "We are not comparing models or making changes to the model, so we will skip adding a validation set this time. Make sure the test dataset is 20% of the original dataset."
      ],
      "metadata": {
        "id": "CR-vjxr7eWEf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TYCTFDv7hZT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem #3: Import, initialize, and train a Logistic Regression model.**\n",
        "---\n"
      ],
      "metadata": {
        "id": "F24ferHretdr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1br90axohZ7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem #4: Make predictions for the test data.**\n",
        "---\n"
      ],
      "metadata": {
        "id": "kQniEK33e4Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = # COMPLETE THIS LINE\n",
        "\n",
        "y_pred_proba = # COMPLETE THIS LINE\n",
        "\n",
        "y_pred_binary = # COMPLETE THIS LINE"
      ],
      "metadata": {
        "id": "0w102G8chQGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem #5: Print the accuracy score.**\n",
        "---\n"
      ],
      "metadata": {
        "id": "Siq_BcV_fHH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = # WRITE YOUR CODE HERE\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "EQ6nqybXfn4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem #6: Print the classification report.**\n",
        "---"
      ],
      "metadata": {
        "id": "21mQImiffalA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report = # WRITE YOUR CODE HERE\n",
        "print(report)"
      ],
      "metadata": {
        "id": "9ecbSIABfemd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Discussion Question: How did Logistic Regression perform compared to the KNN model in Lab 6?**"
      ],
      "metadata": {
        "id": "Uvy68BYrsX5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "#### **Back to lecture**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YJ_4mcGi-4P0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvDIuw6vlsKN"
      },
      "source": [
        "---\n",
        "## **Part 2: Multiclass Classification**\n",
        "---\n",
        "\n",
        "In this section, we'll learn how to use logistic regression to classify handwritten digits into their respective numerical values. We'll use the digits dataset, which consists of 1797 samples of grayscale images of size 8x8 pixels, each represented as a 64-dimensional feature vector. The goal is to classify each image into one of 10 classes (corresponding to the 10 digits)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem #7: Load and plot the data.**\n",
        "---\n",
        "\n",
        "We will provide code to load the data into a dataframe and plot a sample. Separate the data into `X` (features) and `y` (target) variables."
      ],
      "metadata": {
        "id": "h_rgwiuMwJC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_digits()\n",
        "df = pd.DataFrame(data.data, columns=[f'pixel{i}' for i in range(64)])\n",
        "df['target'] = data.target\n",
        "\n",
        "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(8, 6))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(data.images[i], cmap='binary')\n",
        "    ax.set_title(f'Target: {data.target[i]}')\n",
        "plt.show()\n",
        "\n",
        "X = # WRITE YOUR CODE HERE\n",
        "y = # WRITE YOUR CODE HERE"
      ],
      "metadata": {
        "id": "8RfDoanuwvBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem #8: Split the data into train and test sets.**\n",
        "---\n",
        "\n",
        "We are not comparing models or making changes to the model, so we will skip adding a validation set this time. Make sure the test dataset is 20% of the original dataset."
      ],
      "metadata": {
        "id": "gDcW7t2fp-ea"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UzQ0UUAFp-eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem #9: Initialize and train a Logistic Regression model for multiclass classification.**\n",
        "---\n",
        "\n",
        "Use the `ovr` multi-class mode."
      ],
      "metadata": {
        "id": "87lC5-chqG1A"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_sd8SVrmqG1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem #10: Make predictions for the test data.**\n",
        "---\n"
      ],
      "metadata": {
        "id": "9J1bN6WlqG1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = # COMPLETE THIS LINE\n",
        "\n",
        "y_pred_proba = # COMPLETE THIS LINE\n",
        "\n",
        "y_pred_binary = # COMPLETE THIS LINE"
      ],
      "metadata": {
        "id": "JDaBPsREqG1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem #11: Print the accuracy score.**\n",
        "---\n"
      ],
      "metadata": {
        "id": "GJxdjSNoqG1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = # WRITE YOUR CODE HERE\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "rvVSO-lbqG1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem #12: Plot the confusion matrix.**\n",
        "---"
      ],
      "metadata": {
        "id": "1nSajOFvqyGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = # WRITE YOUR CODE HERE\n",
        "disp = # WRITE YOUR CODE HERE\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X6uHrmduW4g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "#### **Back to lecture**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "npMRZWB9-4_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Part 3: Battle of the Titanic Models**\n",
        "---\n",
        "\n",
        "In this part, we will revisit the Titanic dataset from the [Titanic competition on Kaggle](https://www.kaggle.com/c/titanic). In Lab 4, you cleaned the data, created features, encoded features, and visualized the data to understand patterns and trends among passengers who survived. Here, we will take the analysis a step further and use the classification models we have learned about (KNN and Logistic Regression) to make predictions for whether or not a passenger survived. We will validate and improve the models to determine a winner that will make final predictions, which you have the option of submitting to the Kaggle competition if you want to find out the final score.\n"
      ],
      "metadata": {
        "id": "mzisnNcmztgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Part 3.1: Build, Train, and Validate Models**\n",
        "\n",
        "---\n",
        "\n",
        "Recall the steps for validating and improving models:\n",
        "\n",
        "1. **Decide on a metric** as the basis for comparing the models and a target value for that metric\n",
        "2. **Train** the models on the training dataset\n",
        "3. **Evaluate** the models on the validation dataset with the chosen metric\n",
        "4. **Make changes** to the models *if improvements are needed*\n",
        "5. **Repeat** steps 2–4 until target metric is achieved by one or more models.\n",
        "\n",
        "Next lecture, we will discuss advanced methods for validating and improving models. "
      ],
      "metadata": {
        "id": "4KoPcNTgXcbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we'll clean and prepare the data the same way we did in Lab 4. We are creating a function that does all the data preparation. This is good practice to make sure all data is prepared the same way. We will be using the same function on the training data (which we will split further into a train/validation datasets) and the test data set (from Kaggle, we do not have the solutions for this. If you want to see the result, you'll have to submit your predictions to the competition).\n",
        "\n",
        "**This code has been provided for you. Run the cell below.**"
      ],
      "metadata": {
        "id": "mVMG7_fG13GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_titanic_data(input_data):\n",
        "  # We will create a copy and preserve the original dataframe\n",
        "  data = input_data.copy() \n",
        "\n",
        "  # Clean the data\n",
        "  data.drop_duplicates(inplace=True)\n",
        "  data = data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "  data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
        "  data['Age'] = data['Age'].fillna(data['Age'].median())\n",
        "\n",
        "  # Feature creation\n",
        "  data.loc[data['Age'] < 18, 'AgeGroup'] = 'Child'\n",
        "  data.loc[(data['Age'] >= 18) & (data['Age'] < 65), 'AgeGroup'] = 'Adult'\n",
        "  data.loc[data['Age'] >= 65, 'AgeGroup'] = 'Elderly'\n",
        "\n",
        "  data['FareGroup'] = pd.qcut(data['Fare'], 4, labels=['Cheap','Low','High','Expensive'])\n",
        "  data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
        "\n",
        "  # Feature encoding\n",
        "  label_map = {'male': 0, 'female': 1}\n",
        "  data['Sex_encoded'] = data['Sex'].map(label_map)\n",
        "\n",
        "  label_map = {'Child': 0, 'Adult': 1, 'Elderly': 2}\n",
        "  data['AgeGroup_encoded'] = data['AgeGroup'].map(label_map)\n",
        "\n",
        "  fare_map = {'Cheap': 0, 'Low': 1, 'High': 2, 'Expensive': 3}\n",
        "  data['FareGroup_encoded'] = data['FareGroup'].map(fare_map)\n",
        "\n",
        "  embark_map = {'S': 0, 'C': 1, 'Q': 2}\n",
        "  data['Embarked_encoded'] = data['Embarked'].map(embark_map)\n",
        "  \n",
        "  return data"
      ],
      "metadata": {
        "id": "jsGDf1Tg3I0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to load and apply the function to preprocess the train and test data. \n",
        "\n",
        "**This code has been provided for you. Run the cell below.**"
      ],
      "metadata": {
        "id": "o4t9jLZG9aLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Kaggle train and test data\n",
        "train_data = pd.read_csv(\"https://raw.githubusercontent.com/n-sachdeva/titanic/main/train.csv\")\n",
        "test_data = pd.read_csv(\"https://raw.githubusercontent.com/n-sachdeva/titanic/main/test.csv\")\n",
        "\n",
        "# Use preprocessing function on both train and test data\n",
        "train = prepare_titanic_data(train_data)\n",
        "test = prepare_titanic_data(test_data)\n",
        "\n",
        "# Select features to use for modeling\n",
        "features = [\"Sex_encoded\",\"Pclass\", \"FamilySize\", \n",
        "            \"AgeGroup_encoded\", \"FareGroup_encoded\", \"Embarked_encoded\"]\n",
        "\n",
        "# Separate features and target\n",
        "X = train[features]\n",
        "y = train['Survived']\n",
        "X_test = test[features]\n",
        "# there is no y_test, because we do not have the truth values for the test set"
      ],
      "metadata": {
        "id": "PMSBLlM81-Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem #13: Split the train data into a training and validation datasets.**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "B1sC32scyCgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train data into train/validation data\n",
        "X_train, X_valid, y_train, y_valid = # WRITE YOUR CODE HERE"
      ],
      "metadata": {
        "id": "g1AcTFo3yCGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem #14: Initialize a logistic regression model, a KNN model with k=3, and a KNN model with k=5.**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yrf53VmdyZ2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create models\n",
        "logr = # WRITE YOUR CODE HERE\n",
        "knn3 = # WRITE YOUR CODE HERE\n",
        "knn5 = # WRITE YOUR CODE HERE"
      ],
      "metadata": {
        "id": "dkRTA-h6yiEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<center>\n",
        "\n",
        "#### **Back to lecture**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "1Qj3GAOUawdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step #1: Decide on a metric and target value**\n",
        "---\n",
        "\n",
        "There are many choices for metrics to use. In this case we will use accuracy, and set a target value of 0.8. These can be changed later if we learn something from the validation process that suggests this may not be the best metric or target.\n"
      ],
      "metadata": {
        "id": "3TJ6CbLh-rxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step #2: Train the models on the training set.**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "psLnGYFO-wo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem 15: Train each of the models: `logr`, `knn3`, and `knn5`.**\n",
        "---"
      ],
      "metadata": {
        "id": "8uKTdT2ky5nd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TY_phiPd-wo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step #3: Evaluate**\n",
        "---\n",
        "\n",
        "Now, we can check the accuracy of each model on the training and validation datasets.\n"
      ],
      "metadata": {
        "id": "ccqSCuOI-zY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem 16: Evaluate and print the accuracy scores.**\n",
        "---\n",
        "\n",
        "Fill in the code where indicated to print the accuracy scores on the training and validation datasets."
      ],
      "metadata": {
        "id": "cGMTP-V9y9Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print training and validation scores\n",
        "models = [logr, knn3, knn5]\n",
        "model_names = ['Logistic Regression', 'KNN-3', 'KNN-5']\n",
        "\n",
        "# Looping over models to print scores for each\n",
        "for model, name in zip(models, model_names):\n",
        "  train_predictions = model.predict(# FILL IN CODE HERE)\n",
        "  train_score = accuracy_score(# FILL IN CODE HERE)\n",
        "  print(name)\n",
        "  print(f'Training Accuracy: {train_score}')\n",
        "  validation_predictions = model.predict(# FILL IN CODE HERE)\n",
        "  validation_score = accuracy_score(# FILL IN CODE HERE)\n",
        "  print(f'Validation Accuracy: {validation_score}\\n')\n"
      ],
      "metadata": {
        "id": "xs7P2dURclkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Discussion Questions**\n",
        "\n",
        "* Did any of the models reach the target value on the validation set? \n",
        "* What trends do you notice in the results?\n",
        "* Did any models show signs of overfitting or underfitting? How so?"
      ],
      "metadata": {
        "id": "HQwbAx2sb0MP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Problem 17: Which model performed best?**"
      ],
      "metadata": {
        "id": "5e05aPgwcOwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "winning_model = # ADD THE WINNING MODEL HERE"
      ],
      "metadata": {
        "id": "DiXqNt7V4xw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **[OPTIONAL] Part 3.2: Make Final Predictions**  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "d5FBkljT-GNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can make final predictions. This dataset is from the [Kaggle Titanic competition](https://www.kaggle.com/c/titanic). There is a test dataset from the competition we can use for final predictions. **We do not have the solutions for the test data.** We will provide code to generate a submission file you can upload on Kaggle if you'd like to submit your work and see the score on Kaggle. You will need to create a Kaggle account to do so. As you progress in this course, feel free to apply your knowledge to improve the features and models in this notebook and resubmit your predictions on Kaggle.\n",
        "\n",
        "Run the cell below. The file `submission.csv` will appear in your file explorer on the left side panel. You may download it to your computer and upload it to the competition to see your score."
      ],
      "metadata": {
        "id": "L0JWmIrUSqwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = winning_model.predict(X_test)\n",
        "\n",
        "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
        "output.to_csv('submission.csv', index=False)\n",
        "print(\"Successfully saved!\")"
      ],
      "metadata": {
        "id": "0HCFpQwcSp-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#End of notebook\n",
        "---\n",
        "© 2023 The Coding School, All rights reserved"
      ],
      "metadata": {
        "id": "7dzC09dLlEhm"
      }
    }
  ]
}